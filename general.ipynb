{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import ipympl\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import pandas as pd\n",
    "import math\n",
    "import scipy.io\n",
    "import hdf5storage\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "#import matplotlib\n",
    "#matplotlib.use('nbagg')\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats.mstats import gmean \n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks.callbacks import EarlyStopping\n",
    "from tensorflow.python.keras import regularizers\n",
    "from tensorflow.python.keras.regularizers import l2\n",
    "from tensorflow.python.keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, Dropout\n",
    "from tensorflow.python.keras.models import Model\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.cluster import KMeans\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.layers import Average\n",
    "from tensorflow.keras.models import Model\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "assert len(physical_devices) > 0, \"Not enough GPU hardware devices available\"\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.callbacks import TensorBoard\n",
    "#indicate folder to save, plus other options\n",
    "tensorboard = TensorBoard(log_dir='./logs/run', histogram_freq=0,\n",
    "    write_graph=True, write_images=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 10\n",
    "noise_amount = 2\n",
    "sparse_g = False\n",
    "sparsity_g = 1\n",
    "kernel_g = 0\n",
    "bias_g = 0\n",
    "dropout_g = False\n",
    "dropoutRate_g = 0.1\n",
    "message = \"\"\n",
    "\n",
    "simple = True\n",
    "contracting = False\n",
    "sparse = False\n",
    "sparseDropout = False\n",
    "denoising = False\n",
    "\n",
    "if(simple):\n",
    "    sparse_g = False\n",
    "    sparsity_g = 1\n",
    "    kernel_g = 0\n",
    "    bias_g = 0\n",
    "    dropout_g = False\n",
    "    dropoutRate_g = 0.1\n",
    "    message = \"simple model\"\n",
    "elif(contracting):\n",
    "    sparse_g = False\n",
    "    sparsity_g = 1\n",
    "    kernel_g = 0.01\n",
    "    bias_g = 0.01\n",
    "    dropout_g = False\n",
    "    dropoutRate_g = 0.1\n",
    "    message = \"contracting model\"\n",
    "elif(sparse):\n",
    "    sparse_g = True\n",
    "    sparsity_g = 1\n",
    "    kernel_g = 0\n",
    "    bias_g = 0\n",
    "    dropout_g = False\n",
    "    dropoutRate_g = 0.1\n",
    "    message = \"sparse model\"\n",
    "elif(sparseDropout):\n",
    "    sparse_g = True\n",
    "    sparsity_g = 1\n",
    "    kernel_g = 0\n",
    "    bias_g = 0\n",
    "    dropout_g = True\n",
    "    dropoutRate_g = 0.1\n",
    "    message = \"sparseDropout model\"\n",
    "elif(denoising):\n",
    "    sparse_g = False\n",
    "    sparsity_g = 1\n",
    "    kernel_g = 0\n",
    "    bias_g = 0\n",
    "    dropout_g = False\n",
    "    dropoutRate_g = 0.1\n",
    "    message = \"denoising model\"\n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Average2(lst): \n",
    "    return sum(lst) / len(lst) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Find_Optimal_Cutoff(target, predicted):\n",
    "    fpr, tpr, threshold = roc_curve(target, predicted)\n",
    "    i = np.arange(len(tpr)) \n",
    "    roc = pd.DataFrame({'tf' : pd.Series(tpr-(1-fpr), index=i), 'threshold' : pd.Series(threshold, index=i)})\n",
    "    roc_t = roc.iloc[(roc.tf-0).abs().argsort()[:1]]\n",
    "\n",
    "    return list(roc_t['threshold']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModel(inputs,table,kernel,bias,sparse,sparsity,dropout,dropoutRate,shape):\n",
    "    for i in range(len(table)):\n",
    "        if(i==0):\n",
    "            if(sparse):\n",
    "                if(dropout):\n",
    "                    encoded = Dense(table[i], activation='relu'\n",
    "                    #,activity_regularizer=regularizers.l1(sparsity)\n",
    "                     )(inputs)\n",
    "                    encoded = Dropout(dropoutRate)(encoded)\n",
    "                else:\n",
    "                    encoded = Dense(table[i], activation='relu'\n",
    "                    #,activity_regularizer=regularizers.l1(sparsity)\n",
    "                     )(inputs)\n",
    "            elif(kernel==0):\n",
    "                encoded = Dense(table[i], activation='relu')(inputs)\n",
    "            else:\n",
    "                encoded = Dense(table[i], activation='relu'\n",
    "                    ,kernel_regularizer=l2(kernel) \n",
    "                    ,bias_regularizer=l2(bias)\n",
    "                    )(inputs)\n",
    "        elif(i==math.floor(len(table)/2)):\n",
    "            if(sparse):\n",
    "                if(dropout):\n",
    "                    encoded = Dense(table[i], activation='relu'\n",
    "                    ,activity_regularizer=regularizers.l1(sparsity)\n",
    "                     )(encoded)\n",
    "                    encoded = Dropout(dropoutRate)(encoded)\n",
    "                else:\n",
    "                    encoded = Dense(table[i], activation='relu'\n",
    "                    ,activity_regularizer=regularizers.l1(sparsity)\n",
    "                     )(encoded)\n",
    "            elif(kernel==0):\n",
    "                encoded = Dense(table[i], activation='relu')(encoded)\n",
    "            else:\n",
    "                encoded = Dense(table[i], activation='relu'\n",
    "                    ,kernel_regularizer=l2(kernel) \n",
    "                    ,bias_regularizer=l2(bias)\n",
    "                    )(encoded)    \n",
    "        else:\n",
    "            if(sparse):\n",
    "                if(dropout):\n",
    "                    encoded = Dense(table[i], activation='relu'\n",
    "                    #,activity_regularizer=regularizers.l1(sparsity)\n",
    "                     )(encoded)\n",
    "                    encoded = Dropout(dropoutRate)(encoded)\n",
    "                else:\n",
    "                    encoded = Dense(table[i], activation='relu'\n",
    "                    #,activity_regularizer=regularizers.l1(sparsity)\n",
    "                     )(encoded)\n",
    "            elif(kernel==0):\n",
    "                encoded = Dense(table[i], activation='relu')(encoded)\n",
    "            else:\n",
    "                encoded = Dense(table[i], activation='relu'\n",
    "                    ,kernel_regularizer=l2(kernel) \n",
    "                    ,bias_regularizer=l2(bias)\n",
    "                )(encoded)\n",
    "    \n",
    "    \n",
    "    if(sparse):\n",
    "        if(dropout):\n",
    "            encodedL = Dense(shape, activation='tanh'\n",
    "            #,activity_regularizer=regularizers.l1(sparsity)\n",
    "                )(encoded)\n",
    "            encodedL = Dropout(dropoutRate)(encodedL)\n",
    "        else:\n",
    "            encodedL = Dense(shape, activation='tanh'\n",
    "            #,activity_regularizer=regularizers.l1(sparsity)\n",
    "                )(encoded)\n",
    "    elif(kernel==0):\n",
    "        encodedL = Dense(shape, activation='tanh')(encoded)\n",
    "    else:\n",
    "        encodedL = Dense(shape, activation='tanh'\n",
    "            ,kernel_regularizer=l2(kernel) \n",
    "            ,bias_regularizer=l2(bias)\n",
    "            )(encoded)        \n",
    "    model = Model(inputs, encodedL)\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    #model.summary()\n",
    "    return model , encodedL\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1831, 21)\n",
      "(1831,)\n",
      "Total number of outliers in Dataset\n",
      "176\n",
      "Contamination in Dataset\n",
      "0.0961223375204806\n",
      "(1655, 21)\n",
      "test_data.shape\n",
      "(352, 22)\n",
      "train_data.shape\n",
      "(1479, 21)\n",
      "(226,)\n",
      "Number of Outliers in Test\n",
      "176\n",
      "Number of Inliers in Test\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "file_name = \"cardio.mat\"\n",
    "#file_name = \"ionosphere.mat\"\n",
    "#file_name = \"satellite.mat\"\n",
    "#file_name = \"shuttle.mat\"\n",
    "#file_name = \"smtp.mat\"\n",
    "#mat = hdf5storage.loadmat('smtp.mat')\n",
    "#file_name = \"wine.mat\"\n",
    "#file_name = \"arrhythmia.mat\"\n",
    "#file_name = \"thyroid.mat\"\n",
    "mat = scipy.io.loadmat(file_name)\n",
    "message = \"best models \"+file_name   \n",
    "epochs = 200\n",
    "# Set callback functions to early stop training and save the best model so far\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=1)]\n",
    "#callbacks = [EarlyStopping(monitor='val_loss', patience=1),tensorboard]\n",
    "Xtemp = mat['X']\n",
    "ytemp = mat['y']\n",
    "X = np.array(Xtemp)\n",
    "y = np.array(ytemp)\n",
    "print(X.shape)\n",
    "y = y.reshape(X.shape[0],)\n",
    "print(y.shape)\n",
    "outliers = 0\n",
    "clean_data = []\n",
    "contam_data = []\n",
    "\n",
    "for i in range(y.shape[0]):\n",
    "    if(y[i]==1.0):\n",
    "        outliers+=1;\n",
    "        contam_data.append(X[i])\n",
    "    else:\n",
    "        clean_data.append(X[i])\n",
    "      \n",
    "\n",
    "print(\"Total number of outliers in Dataset\")        \n",
    "print(outliers)\n",
    "contam = outliers/y.shape[0]\n",
    "print(\"Contamination in Dataset\")\n",
    "print(contam)\n",
    "clean_data = np.array(clean_data)\n",
    "contam_data = np.array(contam_data)\n",
    "print(clean_data.shape)\n",
    "clean_data2 = clean_data.copy()\n",
    "contam_data2 = contam_data.copy()\n",
    "# test_data_full = []\n",
    "# for i in range(176):\n",
    "#     test_data_full.append(contam_data[i])\n",
    "# one = np.ones(176)\n",
    "# test_data_full = np.array(test_data_full)\n",
    "\n",
    "# test_data_full= np.append(test_data_full,one,1)\n",
    "\n",
    "# print(test_data_full.shape)\n",
    "\n",
    "Xy = X.copy()\n",
    "Xy.shape\n",
    "Xy = np.array(Xy)\n",
    "Xy = np.insert(Xy, X.shape[1], y, axis=1)\n",
    "#print(Xy.shape)\n",
    "count = outliers\n",
    "count2 = outliers\n",
    "\n",
    "\n",
    "    \n",
    "#selecting all the outliers from dataset\n",
    "test_data =[]\n",
    "for i in range(Xy.shape[0]):\n",
    "    if(Xy[i,X.shape[1]]==1 and count>0):\n",
    "        test_data.append(Xy[i])\n",
    "        count = count-1\n",
    "    \n",
    "test_data = np.array(test_data)\n",
    "\n",
    "#selecting random inliers from train data and removing them\n",
    "indexes = np.random.choice(clean_data.shape[0], outliers, replace=False)\n",
    "\n",
    "random_clean_data = clean_data[indexes, :]\n",
    "random_clean_data = np.hstack((random_clean_data, np.zeros((random_clean_data.shape[0], 1), dtype=random_clean_data.dtype)))\n",
    "\n",
    "indexes = indexes.reshape(outliers,1)\n",
    "\n",
    "#deleting the values from train data\n",
    "clean_data = np.delete(clean_data,indexes,0)\n",
    "#print(clean_data)                \n",
    "test_data = np.append(test_data,random_clean_data,axis=0)\n",
    "np.random.shuffle(test_data)\n",
    "\n",
    "print(\"test_data.shape\")\n",
    "print(test_data.shape)\n",
    "#print(test_data.shape)\n",
    "test_x = test_data[:,:test_data.shape[1]-1]\n",
    "test_y = test_data[:,test_data.shape[1]-1]\n",
    "#print(test_x.shape)\n",
    "#print(test_y.shape)\n",
    "test_x = pd.DataFrame(test_x)\n",
    "test_y = pd.DataFrame(test_y)\n",
    "\n",
    "print(\"train_data.shape\")                    \n",
    "print(clean_data.shape)    \n",
    "X_train, X_test = train_test_split(clean_data2,  test_size=0.03, random_state=42)\n",
    "X_test = np.append(X_test,np.zeros((X_test.shape[0],1),dtype='float64'),axis=1)\n",
    "\n",
    "inliers_test = X_test.shape[0]\n",
    "\n",
    "contam_new = contam_data2.shape[0]/X_test.shape[0]\n",
    "contam_data3 = np.append(contam_data2,np.ones((contam_data2.shape[0],1),dtype='float64'),axis=1)\n",
    "outliers_test = contam_data3.shape[0]\n",
    "X_test = np.append(X_test,contam_data3,axis=0)\n",
    "np.random.shuffle(X_test)\n",
    "Xy_test = X_test.copy\n",
    "y_test = X_test[:,X_test.shape[1]-1]\n",
    "#print(y_test.shape)\n",
    "X_test = np.delete(X_test,X_test.shape[1]-1,axis=1)\n",
    "#print(X_test.shape)\n",
    "\n",
    "X_test_np = X_test\n",
    "y_test_np = y_test\n",
    "print(y_test.shape)\n",
    "\n",
    "X_test = pd.DataFrame(X_test)\n",
    "y_test = pd.DataFrame(y_test)\n",
    "print(\"Number of Outliers in Test\")\n",
    "print(outliers_test)\n",
    "print(\"Number of Inliers in Test\")\n",
    "print(inliers_test)\n",
    "#print(X_train)\n",
    "#print(X_train.mean())\n",
    "#print(pd.DataFrame(X_train).describe())\n",
    "X_train_noisy = X_train\n",
    "#noisy data\n",
    "#print(X_train_noisy)\n",
    "def apply_noise(col):\n",
    "    #print(col.mean())\n",
    "    mu, sigma = 0, abs(col.mean())\n",
    "    noise = np.random.normal(mu, sigma, col.shape[0]) \n",
    "    for i  in range(col.shape[0]):\n",
    "        col[i] += noise_amount*noise[i]\n",
    "\n",
    "    return col\n",
    "#print(X_train)\n",
    "X_train_noisy = np.apply_along_axis(apply_noise, 0, X_train)\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "clean_data = scaler.fit_transform(clean_data)\n",
    "test_x  = scaler.transform(test_x)\n",
    "clean_data = pd.DataFrame(clean_data)\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test  = scaler.transform(X_test)\n",
    "clean_data = pd.DataFrame(clean_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9704545454545455\n",
      "0.9760227272727272\n",
      "0.9780681818181818\n",
      "0.9767045454545454\n",
      "0.97625\n",
      "0.9773863636363636\n",
      "0.9747727272727272\n",
      "results\n",
      "0.9026548672566371\n",
      "0.911504424778761\n",
      "0.915929203539823\n",
      "0.911504424778761\n",
      "0.8938053097345132\n",
      "0.9203539823008849\n",
      "0.9070796460176991\n",
      "0.911504424778761\n",
      "0\n",
      "--- 32.902000188827515 seconds ---\n",
      "0.9737500000000001\n",
      "0.9756818181818181\n",
      "0.9744318181818182\n",
      "0.9794318181818181\n",
      "0.9736363636363636\n",
      "0.9781818181818183\n",
      "0.9744318181818181\n",
      "results\n",
      "0.8982300884955752\n",
      "0.911504424778761\n",
      "0.9070796460176991\n",
      "0.9292035398230089\n",
      "0.8893805309734514\n",
      "0.911504424778761\n",
      "0.911504424778761\n",
      "0.9070796460176991\n",
      "1\n",
      "--- 28.40099787712097 seconds ---\n",
      "0.9815909090909091\n",
      "0.97625\n",
      "0.9743181818181819\n",
      "0.9820454545454544\n",
      "0.9667045454545454\n",
      "0.9798863636363636\n",
      "0.9746590909090909\n",
      "results\n",
      "0.915929203539823\n",
      "0.915929203539823\n",
      "0.911504424778761\n",
      "0.9292035398230089\n",
      "0.8805309734513275\n",
      "0.915929203539823\n",
      "0.911504424778761\n",
      "0.911504424778761\n",
      "2\n",
      "--- 28.210001945495605 seconds ---\n",
      "0.93125\n",
      "0.975340909090909\n",
      "0.9746590909090909\n",
      "0.9804545454545455\n",
      "0.9723863636363637\n",
      "0.9785227272727273\n",
      "0.964659090909091\n",
      "results\n",
      "0.8628318584070797\n",
      "0.911504424778761\n",
      "0.9070796460176991\n",
      "0.9336283185840708\n",
      "0.8893805309734514\n",
      "0.9070796460176991\n",
      "0.8849557522123894\n",
      "0.911504424778761\n",
      "3\n",
      "--- 48.30899786949158 seconds ---\n",
      "0.9345454545454546\n",
      "0.9757954545454545\n",
      "0.9748863636363636\n",
      "0.9814772727272727\n",
      "0.9656818181818181\n",
      "0.9770454545454546\n",
      "0.9677272727272728\n",
      "results\n",
      "0.8761061946902655\n",
      "0.911504424778761\n",
      "0.911504424778761\n",
      "0.9380530973451328\n",
      "0.8982300884955752\n",
      "0.8982300884955752\n",
      "0.9026548672566371\n",
      "0.911504424778761\n",
      "4\n",
      "--- 44.76299786567688 seconds ---\n",
      "0.9575\n",
      "0.9761363636363636\n",
      "0.974090909090909\n",
      "0.9774999999999999\n",
      "0.9770454545454546\n",
      "0.9801136363636364\n",
      "0.9667045454545454\n",
      "results\n",
      "0.8938053097345132\n",
      "0.911504424778761\n",
      "0.911504424778761\n",
      "0.9247787610619469\n",
      "0.9070796460176991\n",
      "0.9203539823008849\n",
      "0.8982300884955752\n",
      "0.911504424778761\n",
      "5\n",
      "--- 52.80000042915344 seconds ---\n",
      "0.9686363636363635\n",
      "0.9765909090909091\n",
      "0.9742045454545454\n",
      "0.9835227272727272\n",
      "0.9711363636363636\n",
      "0.9761363636363636\n",
      "0.9748863636363636\n",
      "results\n",
      "0.8893805309734514\n",
      "0.915929203539823\n",
      "0.911504424778761\n",
      "0.9336283185840708\n",
      "0.8849557522123894\n",
      "0.911504424778761\n",
      "0.9070796460176991\n",
      "0.9070796460176991\n",
      "6\n",
      "--- 31.07100009918213 seconds ---\n",
      "0.9705681818181817\n",
      "0.9763636363636363\n",
      "0.9739772727272726\n",
      "0.9788636363636364\n",
      "0.9686363636363636\n",
      "0.9770454545454546\n",
      "0.9768181818181818\n",
      "results\n",
      "0.8893805309734514\n",
      "0.911504424778761\n",
      "0.9070796460176991\n",
      "0.9380530973451328\n",
      "0.8805309734513275\n",
      "0.911504424778761\n",
      "0.9026548672566371\n",
      "0.9070796460176991\n",
      "7\n",
      "--- 58.71589994430542 seconds ---\n",
      "0.9851136363636364\n",
      "0.9767045454545453\n",
      "0.9748863636363636\n",
      "0.9813636363636363\n",
      "0.9675\n",
      "0.9786363636363635\n",
      "0.9745454545454546\n",
      "results\n",
      "0.9292035398230089\n",
      "0.911504424778761\n",
      "0.911504424778761\n",
      "0.9292035398230089\n",
      "0.9026548672566371\n",
      "0.9247787610619469\n",
      "0.911504424778761\n",
      "0.9026548672566371\n",
      "8\n",
      "--- 29.526999473571777 seconds ---\n",
      "0.9829545454545454\n",
      "0.9761363636363636\n",
      "0.974090909090909\n",
      "0.9788636363636363\n",
      "0.9738636363636364\n",
      "0.9788636363636364\n",
      "0.9751136363636363\n",
      "results\n",
      "0.915929203539823\n",
      "0.911504424778761\n",
      "0.911504424778761\n",
      "0.9292035398230089\n",
      "0.8938053097345132\n",
      "0.911504424778761\n",
      "0.9070796460176991\n",
      "0.9070796460176991\n",
      "9\n",
      "--- 28.586999654769897 seconds ---\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for k in range(iterations): \n",
    "    tf.keras.backend.clear_session()\n",
    "    start_time = time.time()\n",
    "    models = []\n",
    "    outs = []\n",
    "    mses = []\n",
    "    aucs = []\n",
    "    inputs = Input(shape=(X.shape[1],))\n",
    "    \n",
    "#     table = [5000,2000,1000,500,300,200,100,70,40,10,40,70,100,200,300,500,1000,2000,5000]\n",
    "\n",
    "#     simpleAutoencoder7,simpleAutoencoder_out7 = createModel(inputs,table,kernel_g,bias_g,sparse_g,sparsity_g,dropout_g,dropoutRate_g,X.shape[1])\n",
    "#     models.append(simpleAutoencoder7)\n",
    "#     outs.append(simpleAutoencoder_out7)\n",
    "    \n",
    "#     table = [2000,1000,500,300,200,100,70,40,10,40,70,100,200,300,500,1000,2000]\n",
    "\n",
    "#     simpleAutoencoder6,simpleAutoencoder_out6 = createModel(inputs,table,kernel_g,bias_g,sparse_g,sparsity_g,dropout_g,dropoutRate_g,X.shape[1])\n",
    "#     models.append(simpleAutoencoder6)\n",
    "#     outs.append(simpleAutoencoder_out6)\n",
    "    \n",
    "#     table = [500,300,200,100,70,40,10,40,70,100,200,300,500]\n",
    "\n",
    "#     simpleAutoencoder5,simpleAutoencoder_out5 = createModel(inputs,table,kernel_g,bias_g,sparse_g,sparsity_g,dropout_g,dropoutRate_g,X.shape[1])\n",
    "#     models.append(simpleAutoencoder5)\n",
    "#     outs.append(simpleAutoencoder_out5)\n",
    "    \n",
    "#     table = [200,150,100,70,40,10,40,70,100,150,200]\n",
    "\n",
    "#     simpleAutoencoder,simpleAutoencoder_out = createModel(inputs,table,kernel_g,bias_g,sparse_g,sparsity_g,dropout_g,dropoutRate_g,X.shape[1])\n",
    "#     models.append(simpleAutoencoder)\n",
    "#     outs.append(simpleAutoencoder_out)\n",
    "    \n",
    "#     table = [150,100,70,40,10,40,70,100,150]\n",
    "\n",
    "#     simpleAutoencoder2,simpleAutoencoder_out2 = createModel(inputs,table,kernel_g,bias_g,sparse_g,sparsity_g,dropout_g,dropoutRate_g,X.shape[1])\n",
    "#     models.append(simpleAutoencoder2)\n",
    "#     outs.append(simpleAutoencoder_out2)\n",
    "\n",
    "#     table = [100,70,40,10,40,70,100]\n",
    "\n",
    "#     simpleAutoencoder3,simpleAutoencoder_out3 = createModel(inputs,table,kernel_g,bias_g,sparse_g,sparsity_g,dropout_g,dropoutRate_g,X.shape[1])\n",
    "#     models.append(simpleAutoencoder3)\n",
    "#     outs.append(simpleAutoencoder_out3)\n",
    "    \n",
    "#     table = [70,40,10,40,70]\n",
    "\n",
    "#     simpleAutoencoder8,simpleAutoencoder_out8 = createModel(inputs,table,kernel_g,bias_g,sparse_g,sparsity_g,dropout_g,dropoutRate_g,X.shape[1])\n",
    "#     models.append(simpleAutoencoder8)\n",
    "#     outs.append(simpleAutoencoder_out8)\n",
    "    \n",
    "#     table = [40,10,40]\n",
    "\n",
    "#     simpleAutoencoder4,simpleAutoencoder_out4 = createModel(inputs,table,kernel_g,bias_g,sparse_g,sparsity_g,dropout_g,dropoutRate_g,X.shape[1])\n",
    "#     models.append(simpleAutoencoder4)\n",
    "#     outs.append(simpleAutoencoder_out4)\n",
    "    \n",
    "    \n",
    "#     #cardio best archs\n",
    "    \n",
    "    #simple model\n",
    "    table = [2000,1000,500,300,200,100,70,40,10,40,70,100,200,300,500,1000,2000]\n",
    "    simpleAutoencoder1,simpleAutoencoder_out1 = createModel(inputs,table,0,0,False,1,False,0.1,X.shape[1])\n",
    "    models.append(simpleAutoencoder1)\n",
    "    outs.append(simpleAutoencoder_out1)\n",
    "    \n",
    "    #contracting model\n",
    "    table = [100,70,40,10,40,70,100]\n",
    "\n",
    "    simpleAutoencoder3,simpleAutoencoder_out3 = createModel(inputs,table,0.01,0.01,False,1,False,0.1,X.shape[1])\n",
    "    models.append(simpleAutoencoder3)\n",
    "    outs.append(simpleAutoencoder_out3)\n",
    "    \n",
    "    #sparse model\n",
    "    simpleAutoencoder2,simpleAutoencoder_out2 = createModel(inputs,table,0,0,True,1,False,0.1,X.shape[1])\n",
    "    models.append(simpleAutoencoder2)\n",
    "    outs.append(simpleAutoencoder_out2)\n",
    "    #sparse dropout model\n",
    "    table = [2000,1000,500,300,200,100,70,40,10,40,70,100,200,300,500,1000,2000]\n",
    "    simpleAutoencoder6,simpleAutoencoder_out6 = createModel(inputs,table,0,0,True,1,True,0.1,X.shape[1])\n",
    "    models.append(simpleAutoencoder6)\n",
    "    outs.append(simpleAutoencoder_out6)\n",
    "    #denoising model\n",
    "    table = [5000,2000,1000,500,300,200,100,70,40,10,40,70,100,200,300,500,1000,2000,5000]\n",
    "\n",
    "    simpleAutoencoder7,simpleAutoencoder_out7 = createModel(inputs,table,kernel_g,bias_g,sparse_g,sparsity_g,dropout_g,dropoutRate_g,X.shape[1])\n",
    "    models.append(simpleAutoencoder7)\n",
    "    outs.append(simpleAutoencoder_out7)\n",
    "    \n",
    "    \n",
    "#     #ion best archs\n",
    "    \n",
    "#     #simple model\n",
    "#     table = [100,70,40,10,40,70,100]\n",
    "#     simpleAutoencoder1,simpleAutoencoder_out1 = createModel(inputs,table,0,0,False,1,False,0.1,X.shape[1])\n",
    "#     models.append(simpleAutoencoder1)\n",
    "#     outs.append(simpleAutoencoder_out1)\n",
    "    \n",
    "#     #contracting model\n",
    "#     table = [200,100,70,40,10,40,70,100,200]\n",
    "\n",
    "#     simpleAutoencoder3,simpleAutoencoder_out3 = createModel(inputs,table,0.01,0.01,False,1,False,0.1,X.shape[1])\n",
    "#     models.append(simpleAutoencoder3)\n",
    "#     outs.append(simpleAutoencoder_out3)\n",
    "    \n",
    "#     #sparse model\n",
    "#     table = [100,70,40,10,40,70,100]\n",
    "    \n",
    "#     simpleAutoencoder2,simpleAutoencoder_out2 = createModel(inputs,table,0,0,True,1,False,0.1,X.shape[1])\n",
    "#     models.append(simpleAutoencoder2)\n",
    "#     outs.append(simpleAutoencoder_out2)\n",
    "#     #sparse dropout model\n",
    "    \n",
    "#     simpleAutoencoder6,simpleAutoencoder_out6 = createModel(inputs,table,0,0,True,1,True,0.1,X.shape[1])\n",
    "#     models.append(simpleAutoencoder6)\n",
    "#     outs.append(simpleAutoencoder_out6)\n",
    "#     #denoising model\n",
    "#     table = [200,100,70,40,10,40,70,100,200]\n",
    "\n",
    "#     simpleAutoencoder7,simpleAutoencoder_out7 = createModel(inputs,table,kernel_g,bias_g,sparse_g,sparsity_g,dropout_g,dropoutRate_g,X.shape[1])\n",
    "#     models.append(simpleAutoencoder7)\n",
    "#     outs.append(simpleAutoencoder_out7)\n",
    "    \n",
    "    \n",
    "#      #sat best archs\n",
    "    \n",
    "#     #simple model\n",
    "#     table = [2000,1000,500,300,200,100,70,40,10,40,70,100,200,300,500,1000,2000]\n",
    "#     simpleAutoencoder1,simpleAutoencoder_out1 = createModel(inputs,table,0,0,False,1,False,0.1,X.shape[1])\n",
    "#     models.append(simpleAutoencoder1)\n",
    "#     outs.append(simpleAutoencoder_out1)\n",
    "    \n",
    "#     #contracting model\n",
    "    \n",
    "\n",
    "#     simpleAutoencoder3,simpleAutoencoder_out3 = createModel(inputs,table,0.01,0.01,False,1,False,0.1,X.shape[1])\n",
    "#     models.append(simpleAutoencoder3)\n",
    "#     outs.append(simpleAutoencoder_out3)\n",
    "    \n",
    "#     #sparse model\n",
    "    \n",
    "    \n",
    "#     simpleAutoencoder2,simpleAutoencoder_out2 = createModel(inputs,table,0,0,True,1,False,0.1,X.shape[1])\n",
    "#     models.append(simpleAutoencoder2)\n",
    "#     outs.append(simpleAutoencoder_out2)\n",
    "#     #sparse dropout model\n",
    "    \n",
    "#     simpleAutoencoder6,simpleAutoencoder_out6 = createModel(inputs,table,0,0,True,1,True,0.1,X.shape[1])\n",
    "#     models.append(simpleAutoencoder6)\n",
    "#     outs.append(simpleAutoencoder_out6)\n",
    "#     #denoising model\n",
    "    \n",
    "\n",
    "#     simpleAutoencoder7,simpleAutoencoder_out7 = createModel(inputs,table,0,0,False,1,False,0.1,X.shape[1])\n",
    "#     models.append(simpleAutoencoder7)\n",
    "#     outs.append(simpleAutoencoder_out7)\n",
    "    \n",
    "    \n",
    "\n",
    "#     for i in range(len(models)):\n",
    "#         if(denoising):\n",
    "#             models[i].fit(X_train_noisy, X_train,\n",
    "#                             epochs=epochs,\n",
    "#                             batch_size=256,\n",
    "#                             shuffle=True,\n",
    "#                             callbacks=callbacks,\n",
    "#                             validation_split=0.4,\n",
    "#                             verbose=0\n",
    "#                            )\n",
    "#             decoded = models[i].predict(X_test)\n",
    "#             mse = np.mean(np.power(X_test - decoded, 2), axis=1)\n",
    "#             mse = mse.reshape(-1, 1)\n",
    "#             scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "#             mse = scaler.fit_transform(mse)\n",
    "#             mses.append(mse)\n",
    "#         else:\n",
    "#             models[i].fit(X_train, X_train,\n",
    "#                             epochs=epochs,\n",
    "#                             batch_size=256,\n",
    "#                             shuffle=True,\n",
    "#                             callbacks=callbacks,\n",
    "#                             validation_split=0.4,\n",
    "#                             verbose=0\n",
    "#                            )\n",
    "#             decoded = models[i].predict(X_test)\n",
    "#             mse = np.mean(np.power(X_test - decoded, 2), axis=1)\n",
    "#             mse = mse.reshape(-1, 1)\n",
    "#             scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "#             mse = scaler.fit_transform(mse)\n",
    "#             mses.append(mse)\n",
    "            \n",
    "            \n",
    "    for i in range(len(models)):\n",
    "        if(i<(len(models)-1)):\n",
    "            models[i].fit(X_train, X_train,\n",
    "                            epochs=epochs,\n",
    "                            batch_size=256,\n",
    "                            shuffle=True,\n",
    "                            callbacks=callbacks,\n",
    "                            validation_split=0.4,\n",
    "                            verbose=0\n",
    "                           )\n",
    "            decoded = models[i].predict(X_test)\n",
    "            mse = np.mean(np.power(X_test - decoded, 2), axis=1)\n",
    "            mse = mse.reshape(-1, 1)\n",
    "            scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "            mse = scaler.fit_transform(mse)\n",
    "            mses.append(mse)\n",
    "        else:\n",
    "            models[i].fit(X_train_noisy, X_train,\n",
    "                            epochs=epochs,\n",
    "                            batch_size=256,\n",
    "                            shuffle=True,\n",
    "                            callbacks=callbacks,\n",
    "                            validation_split=0.4,\n",
    "                            verbose=0\n",
    "                           )\n",
    "            decoded = models[i].predict(X_test)\n",
    "            mse = np.mean(np.power(X_test - decoded, 2), axis=1)\n",
    "            mse = mse.reshape(-1, 1)\n",
    "            scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "            mse = scaler.fit_transform(mse)\n",
    "            mses.append(mse)\n",
    "        \n",
    "    \n",
    "    temp = np.array(mses)\n",
    "    ensemble = (np.sum(temp,axis = 0)/(len(mses)))\n",
    "    #print(ensemble)\n",
    "    mses.append(ensemble)\n",
    "    \n",
    "    \n",
    "  \n",
    "    #x = concatenate([decoded3_de2, decoded3_s3,decoded3,decoded3_s2])  # merge the outputs of the two models\n",
    "    x = Average()(outs) \n",
    "\n",
    "    out = Dense(X.shape[1],activation='tanh'\n",
    "                #, kernel_regularizer=l2(kernel_reg) \n",
    "                #, bias_regularizer=l2(bias_reg)\n",
    "               )(x)  # final layer of the network\n",
    "    Emodel = Model(inputs=inputs, outputs=out)\n",
    "    for l in Emodel.layers:\n",
    "        l.trainable = False\n",
    "\n",
    "    Emodel.layers[len(Emodel.layers)-1].trainable = True\n",
    "\n",
    "    Emodel.compile(optimizer='adam', loss='mse')\n",
    "    Emodel.fit(X_train, X_train,\n",
    "                    epochs=500,\n",
    "                    batch_size=256,\n",
    "                    shuffle=True,\n",
    "                    callbacks=callbacks,\n",
    "                    validation_split=0.4,\n",
    "                    verbose=0\n",
    "    )\n",
    "\n",
    "    ensemble_pred = Emodel.predict(X_test)\n",
    "    #print(ensemble_pred)\n",
    "    ensemble2_mse = np.mean(np.power(X_test - ensemble_pred, 2), axis=1)\n",
    "    ensemble2_mse = ensemble2_mse.reshape(-1, 1)\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    ensemble2_mse = scaler.fit_transform(ensemble2_mse)\n",
    "    #print(ensemble2_mse)\n",
    "    mses.append(ensemble2_mse)\n",
    "    \n",
    "    for i in range(len(mses)):\n",
    "        \n",
    "        fpr_keras3, tpr_keras3, thresholds_keras3 = roc_curve(y_test, mses[i])\n",
    "        auc_keras3 = auc(fpr_keras3, tpr_keras3)\n",
    "        aucs.append(auc_keras3)\n",
    "        #plt.figure(1)\n",
    "        #plt.plot([0, 1], [0, 1], 'k--')\n",
    "\n",
    "        #plt.plot(fpr_keras3, tpr_keras3, label='Keras (area = {:.3f})'.format(auc_keras3))\n",
    "        print(auc_keras3)\n",
    "    #plt.xlabel('False positive rate')\n",
    "    #plt.ylabel('True positive rate')\n",
    "    #plt.title('ROC curve')\n",
    "    #plt.legend(loc='best')\n",
    "    #plt.show()    \n",
    "    \n",
    "    print('results')\n",
    "    \n",
    "    #3% tha thewrw lathos apo ta swsta -> predict apo ta training dedomena gia na vgei to threshold\n",
    "    votes = [];\n",
    "    threshes = [];\n",
    "    for i in range(len(mses)):\n",
    "        threshes.append(Find_Optimal_Cutoff(y_test,mses[i]))\n",
    "    for i in range(len(threshes)):\n",
    "        temp = mses[i]\n",
    "        tempvotes = []\n",
    "        for j in range(len(y_test)):\n",
    "            if(temp[j]>threshes[i]):\n",
    "                tempvotes.append(1)\n",
    "            else:\n",
    "                tempvotes.append(0)\n",
    "        votes.append(tempvotes)\n",
    "    y_test_list = y_test.values.tolist()\n",
    "\n",
    "    results_with_thresh = []\n",
    "    for j in range(len(threshes)):    \n",
    "        sumss = 0;\n",
    "        for i in range(len(y_test_list)):\n",
    "            if(votes[j][i]==y_test_list[i][0]):\n",
    "                sumss = sumss+1\n",
    "        #print(str(vote_result[i])+'\\t '+ str(y_test_list[i]))  \n",
    "        results_with_thresh.append(sumss/len(y_test_list));\n",
    "        print(sumss/len(y_test_list))\n",
    "    \n",
    "    vote_result = []\n",
    "    for i in range(len(y_test_list)):\n",
    "        if((votes[0][i]+votes[1][i]+votes[2][i]+votes[3][i]+votes[4][i])/5>=0.5):\n",
    "            vote_result.append(1)\n",
    "        else:\n",
    "            vote_result.append(0)\n",
    "\n",
    "    sumss = 0;\n",
    "    for i in range(len(y_test_list)):\n",
    "        if(vote_result[i]==y_test_list[i][0]):\n",
    "            sumss = sumss+1\n",
    "        #print(str(vote_result[i])+'\\t '+ str(y_test_list[i]))        \n",
    "    results_with_thresh.append(sumss/len(y_test_list))\n",
    "    print(sumss/len(y_test_list))\n",
    "\n",
    "    if(k==0):\n",
    "        sums = aucs;\n",
    "        sums_votes = results_with_thresh\n",
    "    else:\n",
    "        temp = aucs\n",
    "        temp2 = results_with_thresh\n",
    "        for tempi in range(0,len(sums)):\n",
    "            sums[tempi] = sums[tempi]+temp[tempi];\n",
    "        for tempi2 in range(0,len(results_with_thresh)):\n",
    "            sums_votes[tempi2] = sums_votes[tempi2]+temp2[tempi2]\n",
    "            \n",
    "            \n",
    "    import csv\n",
    "    from datetime import date\n",
    "    with open('resultsGeneral.csv', 'a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        if(k==iterations-1):\n",
    "            today = date.today()\n",
    "            d1 = today.strftime(\"%d/%m/%Y\")\n",
    "            writer.writerow([d1])\n",
    "            writer.writerow([file_name])\n",
    "            writer.writerow([message])\n",
    "            writer.writerow([\"params\",\"noise_amount\",noise_amount,\"iterations\" ,iterations])\n",
    "            writer.writerow([\"Simple\",\"Contracting\",\"Sparse\",\"Sparse Dropout\",\"Denoising\",\"Ensemble\",\"Ensemble2\"])\n",
    "            #writer.writerow([\"Model 8L\",\"Model 7L\",\"Model 6L\",\"Model 5L\",\"Model 4L\",\"Model 3L\",\"Model 2L\",\"Model 1L\",\"Ensemble\",\"Ensemble2\"])\n",
    "            writer.writerow([x/iterations for x in sums])\n",
    "            writer.writerow(['thresholds']);\n",
    "            writer.writerow(threshes);\n",
    "            writer.writerow(['results']);\n",
    "            writer.writerow([\"Simple\",\"Contracting\",\"Sparse\",\"Sparse Dropout\",\"Denoising\",\"Ensemble\",\"Ensemble2\",\"Voting\"])\n",
    "            writer.writerow([x/iterations for x in sums_votes]);\n",
    "    print(k)\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1968456033416146]\n"
     ]
    }
   ],
   "source": [
    "print(Find_Optimal_Cutoff(y_test,mses[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9829545454545454\n",
      "0.9761363636363636\n",
      "0.974090909090909\n",
      "0.9788636363636363\n",
      "0.9738636363636364\n",
      "0.9788636363636364\n",
      "0.9751136363636363\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(len(mses)):\n",
    "        \n",
    "        fpr_keras3, tpr_keras3, thresholds_keras3 = roc_curve(y_test, mses[i])\n",
    "        auc_keras3 = auc(fpr_keras3, tpr_keras3)\n",
    "        #aucs.append(auc_keras3)\n",
    "        plt.figure(1)\n",
    "        plt.plot([0, 1], [0, 1], 'k--')\n",
    "\n",
    "        plt.plot(fpr_keras3, tpr_keras3, label='Keras (area = {:.3f})'.format(auc_keras3))\n",
    "        print(auc_keras3)\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.915929203539823\n",
      "1\n",
      "0.911504424778761\n",
      "2\n",
      "0.911504424778761\n",
      "3\n",
      "0.9292035398230089\n",
      "4\n",
      "0.8938053097345132\n",
      "5\n",
      "0.911504424778761\n",
      "6\n",
      "0.9070796460176991\n"
     ]
    }
   ],
   "source": [
    "votes = [];\n",
    "threshes = [];\n",
    "#pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "#print(y_test)\n",
    "for i in range(len(mses)):\n",
    "    threshes.append(Find_Optimal_Cutoff(y_test,mses[i]))\n",
    "#print(mses[0])\n",
    "for i in range(len(threshes)):\n",
    "    temp = mses[i]\n",
    "    tempvotes = []\n",
    "    for j in range(len(y_test)):\n",
    "        if(temp[j]>threshes[i]):\n",
    "            tempvotes.append(1)\n",
    "        else:\n",
    "            tempvotes.append(0)\n",
    "    votes.append(tempvotes)\n",
    "votes = np.array(votes)\n",
    "#print([pd.DataFrame(votes[0]),y_test])\n",
    "#print(pd.concat([pd.DataFrame(votes[0]), y_test], axis=1))\n",
    "\n",
    "\n",
    "y_test_list = y_test.values.tolist()\n",
    "for j in range(len(threshes)):    \n",
    "    sumss = 0;\n",
    "    for i in range(len(y_test_list)):\n",
    "        if(votes[j][i]==y_test_list[i][0]):\n",
    "            sumss = sumss+1\n",
    "        #print(str(vote_result[i])+'\\t '+ str(y_test_list[i]))  \n",
    "    print(j)\n",
    "    print(sumss/len(y_test_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9026548672566371\n"
     ]
    }
   ],
   "source": [
    "vote_result = []\n",
    "for i in range(len(y_test_list)):\n",
    "    if((votes[0][i]+\n",
    "        #votes[1][i]+\n",
    "        #votes[2][i]+\n",
    "        #votes[3][i]+\n",
    "        votes[4][i]+\n",
    "        #votes[5][i]+\n",
    "        votes[6][i]\n",
    "        )/3>=0.5):\n",
    "        vote_result.append(1)\n",
    "    else:\n",
    "        vote_result.append(0)\n",
    "\n",
    "sumss = 0;\n",
    "for i in range(len(y_test_list)):\n",
    "    if(vote_result[i]==y_test_list[i][0]):\n",
    "        sumss = sumss+1\n",
    "    #print(str(vote_result[i])+'\\t '+ str(y_test_list[i]))        \n",
    "print(sumss/len(y_test_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
